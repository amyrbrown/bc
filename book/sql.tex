\chapter{Using Databases and SQL}\label{s:sql}

Almost everyone has used spreadsheets, and almost everyone has
eventually run up against their limitations. The more complicated a data
set is, the harder it is to filter data, express relationships between
different rows and columns, or handle missing values.

Databases pick up where spreadsheets leave off. While they are not as
simple to use if all we want is the sum of a dozen numbers, they can do
a lot of things that spreadsheets can't, on much larger data sets,
faster. And even if we never need to create a database ourselves,
knowing how they work will help us understand why so many of the systems
we use behave the way we do, and why they insist on structuring data in
certain ways.

\section{Selecting Data}

In the late 1920s and early 1930s, William Dyer, Frank Pabodie, and
Valentina Roerich led expeditions to the
\urlfoot{http://en.wikipedia.org/wiki/Pole\_of\_inaccessibility}{Pole of
Inaccessibility} in the South Pacific, and then onward to Antarctica.
Two years ago, their expeditions were found in a storage locker at
Miskatonic University. We have scanned and OCR'd the data they contain,
and we now want to store that information in a way that will make search
and analysis easy.

We basically have three options: text files, a spreadsheet, or a
database. Text files are easiest to create, and work well with version
control, but then we would then have to build search and analysis tools
ourselves. Spreadsheets are good for doing simple analysis, they don't
handle large or complex data sets very well. We would therefore like to
put this data in a database, and these lessons will show how to do that.

\begin{objectives}
\begin{swcitemize}
\item
  Explain the difference between a table, a record, and a field.
\item
  Explain the difference between a database and a database manager.
\item
  Write a query to select all values for specific fields from a single
  table.
\end{swcitemize}
\end{objectives}

\subsection{A Few Definitions}

A \gl{relational database}{g:relational-database} is a way to
store and manipulate information that is arranged as
\gl{tables}{g:table-database}. Each table has columns (also known
as \gl{fields}{g:field-database}) which describe the data, and
rows (also known as \gl{records}{g:record-database}) which contain
the data.

When we are using a spreadsheet, we put formulas into cells to calculate
new values based on old ones. When we are using a database, we send
commands (usually called \gl{queries}{g:query}) to a
\gl{database manager}{g:database-manager}: a program that
manipulates the database for us. The database manager does whatever
lookups and calculations the query specifies, returning the results in a
tabular form that we can then use as a starting point for further
queries.

\begin{swcbox}{Compatibility}

Every database manager---Oracle, IBM DB2, PostgreSQL, MySQL, Microsoft
Access, and SQLite---stores data in a different way, so a database
created with one cannot be used directly by another. However, every
database manager can import and export data in a variety of formats, so
it \emph{is} possible to move information from one to another.

\end{swcbox}

Queries are written in a language called \gl{SQL}{g:sql}, which
stands for ``Structured Query Language''. SQL provides hundreds of
different ways to analyze and recombine data; we will only look at a
handful, but that handful accounts for most of what scientists do.

The tables below show the database we will use in our examples:

\textbf{Person}: people who took readings.

\begin{tabular}{lll}
ident & personal & family \\
\hline
dyer & William & Dyer \\
pb & Frank & Pabodie \\
lake & Anderson & Lake \\
roe & Valentina & Roerich \\
danforth & Frank & Danforth \\
\end{tabular}

\textbf{Site}: locations where readings were taken.

\begin{tabular}{lll}
name & lat & long \\
\hline
DR-1 & -49.85 & -128.57 \\
DR-3 & -47.15 & -126.72 \\
MSK-4 & -48.87 & -123.4 \\
\end{tabular}

\textbf{Visited}: when readings were taken at specific sites.

\begin{tabular}{lll}
ident & site & dated \\
\hline
619 & DR-1 & 1927-02-08 \\
622 & DR-1 & 1927-02-10 \\
734 & DR-3 & 1939-01-07 \\
735 & DR-3 & 1930-01-12 \\
751 & DR-3 & 1930-02-26 \\
752 & DR-3 & ~ \\
837 & MSK-4 & 1932-01-14 \\
844 & DR-1 & 1932-03-22 \\
\end{tabular}

\textbf{Survey}: the actual readings.

\begin{tabular}{llll}
taken & person & quant & reading \\
\hline
619 & dyer & rad & 9.82 \\
619 & dyer & sal & 0.13 \\
622 & dyer & rad & 7.8 \\
622 & dyer & sal & 0.09 \\
734 & pb & rad & 8.41 \\
734 & lake & sal & 0.05 \\
734 & pb & temp & -21.5 \\
735 & pb & rad & 7.22 \\
735 & ~ & sal & 0.06 \\
735 & ~ & temp & -26.0 \\
751 & pb & rad & 4.35 \\
751 & pb & temp & -18.5 \\
751 & lake & sal & 0.1 \\
752 & lake & rad & 2.19 \\
752 & lake & sal & 0.09 \\
752 & lake & temp & -16.0 \\
752 & roe & sal & 41.6 \\
837 & lake & rad & 1.46 \\
837 & lake & sal & 0.21 \\
837 & roe & sal & 22.5 \\
844 & roe & rad & 11.25 \\
\end{tabular}

Notice that three entries---one in the \code{Visited} table, and two
in the \code{Survey} table---are shown in red because they don't
contain any actual data: we'll return to these missing values
\gl{later}{s:null}. For now, let's write an SQL query that
displays scientists' names. We do this using the SQL command
\code{select}, giving it the names of the columns we want and the
table we want them from. Our query and its output look like this:

\begin{VerbIn}
select family, personal from Person;
\end{VerbIn}

\begin{sqltable}{ll}
Dyer & William \\
Pabodie & Frank \\
Lake & Anderson \\
Roerich & Valentina \\
Danforth & Frank \\
\end{sqltable}

The semi-colon at the end of the query tells the database manager that
the query is complete and ready to run. We have written our commands and
column names in lower case, and the table name in Title Case, but we
don't have to: as the example below shows, SQL is
\gl{case insensitive}{g:case-insensitive}.

\begin{VerbIn}
SeLeCt FaMiLy, PeRsOnAl FrOm PeRsOn;
\end{VerbIn}

\begin{sqltable}{ll}
Dyer & William \\
Pabodie & Frank \\
Lake & Anderson \\
Roerich & Valentina \\
Danforth & Frank \\
\end{sqltable}

Whatever casing convention you choose, please be consistent: complex
queries are hard enough to read without the extra cognitive load of
random capitalization.

Going back to our query, it's important to understand that the rows and
columns in a database table aren't actually stored in any particular
order. They will always be \emph{displayed} in some order, but we can
control that in various ways. For example, we could swap the columns in
the output by writing our query as:

\begin{VerbIn}
select personal, family from Person;
\end{VerbIn}

\begin{sqltable}{ll}
William & Dyer \\
Frank & Pabodie \\
Anderson & Lake \\
Valentina & Roerich \\
Frank & Danforth \\
\end{sqltable}

or even repeat columns:

\begin{VerbIn}
select ident, ident, ident from Person;
\end{VerbIn}

\begin{sqltable}{lll}
dyer & dyer & dyer \\
pb & pb & pb \\
lake & lake & lake \\
roe & roe & roe \\
danforth & danforth & danforth \\
\end{sqltable}

As a shortcut, we can select all of the columns in a table using
\code{*}:

\begin{VerbIn}
select * from Person;
\end{VerbIn}

\begin{sqltable}{lll}
dyer & William & Dyer \\
pb & Frank & Pabodie \\
lake & Anderson & Lake \\
roe & Valentina & Roerich \\
danforth & Frank & Danforth \\
\end{sqltable}

\begin{challenge}
  Write a query that selects only site names from the \code{Site}
  table.
\end{challenge}

\begin{challenge}
  Many people format queries as:

\begin{VerbIn}
SELECT personal, family FROM person;
\end{VerbIn}

  or as:

\begin{VerbIn}
select Personal, Family from PERSON;
\end{VerbIn}

  What style do you find easiest to read, and why?
\end{challenge}

\begin{keypoints}
\begin{swcitemize}
\item
  A relational database stores information in tables, each of which has
  a fixed set of columns and a variable number of records.
\item
  A database manager is a program that manipulates information stored in
  a database.
\item
  We write queries in a specialized language called SQL to extract
  information from databases.
\item
  SQL is case-insensitive.
\end{swcitemize}
\end{keypoints}

\section{Sorting and Removing Duplicates}

\begin{objectives}
\begin{swcitemize}
\item
  Write queries that display results in a particular order.
\item
  Write queries that eliminate duplicate values from data.
\end{swcitemize}
\end{objectives}

Data is often redundant, so queries often return redundant information.
For example, if we select the quantitites that have been measured from
the \code{survey} table, we get this:

\begin{VerbIn}
select quant from Survey;
\end{VerbIn}

\begin{sqltable}{l}
rad \\
sal \\
rad \\
sal \\
rad \\
sal \\
temp \\
rad \\
sal \\
temp \\
rad \\
temp \\
sal \\
rad \\
sal \\
temp \\
sal \\
rad \\
sal \\
sal \\
rad \\
\end{sqltable}

We can eliminate the redundant output to make the result more readable
by adding the \code{distinct} keyword to our query:

\begin{VerbIn}
select distinct quant from Survey;
\end{VerbIn}

\begin{sqltable}{l}
rad \\
sal \\
temp \\
\end{sqltable}

If we select more than one column---for example, both the survey site ID
and the quantity measured---then the distinct pairs of values are
returned:

\begin{VerbIn}
select distinct taken, quant from Survey;
\end{VerbIn}

\begin{sqltable}{ll}
619 & rad \\
619 & sal \\
622 & rad \\
622 & sal \\
734 & rad \\
734 & sal \\
734 & temp \\
735 & rad \\
735 & sal \\
735 & temp \\
751 & rad \\
751 & temp \\
751 & sal \\
752 & rad \\
752 & sal \\
752 & temp \\
837 & rad \\
837 & sal \\
844 & rad \\
\end{sqltable}

Notice in both cases that duplicates are removed even if they didn't
appear to be adjacent in the database. Again, it's important to remember
that rows aren't actually ordered: they're just displayed that way.

\begin{challenge}
  Write a query that selects distinct dates from the \code{Site}
  table.
\end{challenge}

As we mentioned earlier, database records are not stored in any
particular order. This means that query results aren't necessarily
sorted, and even if they are, we often want to sort them in a different
way, e.g., by the name of the project instead of by the name of the
scientist. We can do this in SQL by adding an \code{order by} clause
to our query:

\begin{VerbIn}
select * from Person order by ident;
\end{VerbIn}

\begin{sqltable}{lll}
danforth & Frank & Danforth \\
dyer & William & Dyer \\
lake & Anderson & Lake \\
pb & Frank & Pabodie \\
roe & Valentina & Roerich \\
\end{sqltable}

By default, results are sorted in ascending order (i.e., from least to
greatest). We can sort in the opposite order using \code{desc} (for
``descending''):

\begin{VerbIn}
select * from person order by ident desc;
\end{VerbIn}

\begin{sqltable}{lll}
roe & Valentina & Roerich \\
pb & Frank & Pabodie \\
lake & Anderson & Lake \\
dyer & William & Dyer \\
danforth & Frank & Danforth \\
\end{sqltable}

(And if we want to make it clear that we're sorting in ascending order,
we can use \code{asc} instead of \code{desc}.)

We can also sort on several fields at once. For example, this query
sorts results first in ascending order by \code{taken}, and then in
descending order by \code{person} within each group of equal
\code{taken} values:

\begin{VerbIn}
select taken, person from Survey order by taken asc, person desc;
\end{VerbIn}

\begin{sqltable}{ll}
619 & dyer \\
619 & dyer \\
622 & dyer \\
622 & dyer \\
734 & pb \\
734 & pb \\
734 & lake \\
735 & pb \\
735 & None \\
735 & None \\
751 & pb \\
751 & pb \\
751 & lake \\
752 & roe \\
752 & lake \\
752 & lake \\
752 & lake \\
837 & roe \\
837 & lake \\
837 & lake \\
844 & roe \\
\end{sqltable}

This is easier to understand if we also remove duplicates:

\begin{VerbIn}
select distinct taken, person from Survey order by taken asc, person desc;
\end{VerbIn}

\begin{sqltable}{ll}
619 & dyer \\
622 & dyer \\
734 & pb \\
734 & lake \\
735 & pb \\
735 & None \\
751 & pb \\
751 & lake \\
752 & roe \\
752 & lake \\
837 & roe \\
837 & lake \\
844 & roe \\
\end{sqltable}

\begin{challenge}
  Write a query that returns the distinct dates in the \code{Visited}
  table.
\end{challenge}

\begin{challenge}
  Write a query that displays the full names of the scientists in the
  \code{Person} table, ordered by family name.
\end{challenge}

\begin{keypoints}
\begin{swcitemize}
\item
  The records in a database table are not intrinsically ordered: if we
  want to display them in some order, we must specify that explicitly.
\item
  The values in a database are not guaranteed to be unique: if we want
  to eliminate duplicates, we must specify that explicitly as well.
\end{swcitemize}
\end{keypoints}

\section{Filtering}

\begin{objectives}
\begin{swcitemize}
\item
  Write queries that select records that satisfy user-specified
  conditions.
\item
  Explain the order in which the clauses in a query are executed.
\end{swcitemize}
\end{objectives}

One of the most powerful features of a database is the ability to
\gl{filter}{g:filter} data, i.e., to select only those records
that match certain criteria. For example, suppose we want to see when a
particular site was visited. We can select these records from the
\code{Visited} table by using a \code{where} clause in our query:

\begin{VerbIn}
select * from Visited where site='DR-1';
\end{VerbIn}

\begin{sqltable}{lll}
619 & DR-1 & 1927-02-08 \\
622 & DR-1 & 1927-02-10 \\
844 & DR-1 & 1932-03-22 \\
\end{sqltable}

The database manager executes this query in two stages. First, it checks
at each row in the \code{Visited} table to see which ones satisfy the
\code{where}. It then uses the column names following the
\code{select} keyword to determine what columns to display.

This processing order means that we can filter records using
\code{where} based on values in columns that aren't then displayed
(\figref{f:filter}):

\begin{VerbIn}
select ident from Visited where site='DR-1';
\end{VerbIn}

\begin{sqltable}{l}
619 \\
622 \\
844 \\
\end{sqltable}

\swcgraphics{f:filter}{Filtering in SQL}{novice/sql/img/sql-filter.pdf}{0.75}

We can use many other Boolean operators to filter our data. For example,
we can ask for all information from the DR-1 site collected since 1930:

\begin{VerbIn}
select * from Visited where (site='DR-1') and (dated>='1930-00-00');
\end{VerbIn}

\begin{sqltable}{lll}
844 & DR-1 & 1932-03-22 \\
\end{sqltable}

(The parentheses around the individual tests aren't strictly required,
but they help make the query easier to read.)

\begin{swcbox}{Handling Dates}

Most database managers have a special data type for dates. In fact, many
have two: one for dates, such as ``May 31, 1971'', and one for
durations, such as ``31 days''. SQLite doesn't: instead, it stores dates
as either text (in the ISO-8601 standard format ``YYYY-MM-DD
HH:MM:SS.SSSS''), real numbers (the number of days since November 24,
4714 BCE), or integers (the number of seconds since midnight, January 1,
1970). If this sounds complicated, it is, but not nearly as complicated
as figuring out
\urlfoot{http://en.wikipedia.org/wiki/Swedish\_calendar}{historical dates in
Sweden}.

\end{swcbox}

If we want to find out what measurements were taken by either Lake or
Roerich, we can combine the tests on their names using \code{or}:

\begin{VerbIn}
select * from Survey where person='lake' or person='roe';
\end{VerbIn}

\begin{sqltable}{llll}
734 & lake & sal & 0.05 \\
751 & lake & sal & 0.1 \\
752 & lake & rad & 2.19 \\
752 & lake & sal & 0.09 \\
752 & lake & temp & -16.0 \\
752 & roe & sal & 41.6 \\
837 & lake & rad & 1.46 \\
837 & lake & sal & 0.21 \\
837 & roe & sal & 22.5 \\
844 & roe & rad & 11.25 \\
\end{sqltable}

Alternatively, we can use \code{in} to see if a value is in a specific
set:

\begin{VerbIn}
select * from Survey where person in ('lake', 'roe');
\end{VerbIn}

\begin{sqltable}{llll}
734 & lake & sal & 0.05 \\
751 & lake & sal & 0.1 \\
752 & lake & rad & 2.19 \\
752 & lake & sal & 0.09 \\
752 & lake & temp & -16.0 \\
752 & roe & sal & 41.6 \\
837 & lake & rad & 1.46 \\
837 & lake & sal & 0.21 \\
837 & roe & sal & 22.5 \\
844 & roe & rad & 11.25 \\
\end{sqltable}

We can combine \code{and} with \code{or}, but we need to be careful
about which operator is executed first. If we \emph{don't} use
parentheses, we get this:

\begin{VerbIn}
select * from Survey where quant='sal' and person='lake' or person='roe';
\end{VerbIn}

\begin{sqltable}{llll}
734 & lake & sal & 0.05 \\
751 & lake & sal & 0.1 \\
752 & lake & sal & 0.09 \\
752 & roe & sal & 41.6 \\
837 & lake & sal & 0.21 \\
837 & roe & sal & 22.5 \\
844 & roe & rad & 11.25 \\
\end{sqltable}

which is salinity measurements by Lake, and \emph{any} measurement by
Roerich. We probably want this instead:

\begin{VerbIn}
select * from Survey where quant='sal' and (person='lake' or person='roe');
\end{VerbIn}

\begin{sqltable}{llll}
734 & lake & sal & 0.05 \\
751 & lake & sal & 0.1 \\
752 & lake & sal & 0.09 \\
752 & roe & sal & 41.6 \\
837 & lake & sal & 0.21 \\
837 & roe & sal & 22.5 \\
\end{sqltable}

Finally, we can use \code{distinct} with \code{where} to give a
second level of filtering:

\begin{VerbIn}
select distinct person, quant from Survey where person='lake' or person='roe';
\end{VerbIn}

\begin{sqltable}{ll}
lake & sal \\
lake & rad \\
lake & temp \\
roe & sal \\
roe & rad \\
\end{sqltable}

But remember: \code{distinct} is applied to the values displayed in
the chosen columns, not to the entire rows as they are being processed.

\begin{swcbox}{Growing Queries}

What we have just done is how most people ``grow'' their SQL queries. We
started with something simple that did part of what we wanted, then
added more clauses one by one, testing their effects as we went. This is
a good strategy---in fact, for complex queries it's often the
\emph{only} strategy---but it depends on quick turnaround, and on us
recognizing the right answer when we get it.

The best way to achieve quick turnaround is often to put a subset of
data in a temporary database and run our queries against that, or to
fill a small database with synthesized records. For example, instead of
trying our queries against an actual database of 20 million Australians,
we could run it against a sample of ten thousand, or write a small
program to generate ten thousand random (but plausible) records and use
that.

\end{swcbox}

\begin{challenge}
  Suppose we want to select all sites that lie more than 30{\degree} from the
  poles. Our first query is:

\begin{VerbIn}
select * from Site where (lat > -60) or (lat < 60);
\end{VerbIn}

  Explain why this is wrong, and rewrite the query so that it is
  correct.
\end{challenge}

\begin{challenge}
  Normalized salinity readings are supposed to be between 0.0 and 1.0.
  Write a query that selects all records from \code{Survey} with
  salinity values outside this range.
\end{challenge}

\begin{challenge}
  The SQL test \code{*column-name* like *pattern*} is true if the
  value in the named column matches the pattern given; the character
  `\%' can be used any number of times in the pattern to mean ``match
  zero or more characters''.

  \begin{tabular}{ll}
    Expression & Value \\
    \code{'a' like 'a'} & True \\
    \code{'a' like '\%a'} & True \\
    \code{'b' like '\%a'} & False \\
    \code{'alpha' like 'a\%'} & True \\
    \code{'alpha' like 'a\%p\%'} & True \\
  \end{tabular}

  The expression \code{*column-name* not like *pattern*} inverts the
  test. Using \code{like}, write a query that finds all the records in
  \code{Visited} that \emph{aren't} from sites labelled
  `DR-something'.
\end{challenge}

\begin{keypoints}
\begin{swcitemize}
\item
  Use \code{where} to filter records according to Boolean conditions.
\item
  Filtering is done on whole records, so conditions can use fields that
  are not actually displayed.
\end{swcitemize}
\end{keypoints}

\section{Calculating New Values}

\begin{objectives}
\begin{swcitemize}
\item
  Write queries that calculate new values for each selected record.
\end{swcitemize}
\end{objectives}

After carefully re-reading the expedition logs, we realize that the
radiation measurements they report may need to be corrected upward by
5\%. Rather than modifying the stored data, we can do this calculation
on the fly as part of our query:

\begin{VerbIn}
select 1.05 * reading from Survey where quant='rad';
\end{VerbIn}

\begin{sqltable}{l}
10.311 \\
8.19 \\
8.8305 \\
7.581 \\
4.5675 \\
2.2995 \\
1.533 \\
11.8125 \\
\end{sqltable}

When we run the query, the expression \code{1.05 * reading} is
evaluated for each row. Expressions can use any of the fields, all of
usual arithmetic operators, and a variety of common functions. (Exactly
which ones depends on which database manager is being used.) For
example, we can convert temperature readings from Fahrenheit to Celsius
and round to two decimal places:

\begin{VerbIn}
select taken, round(5*(reading-32)/9, 2) from Survey where quant='temp';
\end{VerbIn}

\begin{sqltable}{ll}
734 & -29.72 \\
735 & -32.22 \\
751 & -28.06 \\
752 & -26.67 \\
\end{sqltable}

We can also combine values from different fields, for example by using
the string concatenation operator \code{\textbar{}\textbar{}}:

\begin{VerbIn}
select personal || ' ' || family from Person;
\end{VerbIn}

\begin{sqltable}{l}
William Dyer \\
Frank Pabodie \\
Anderson Lake \\
Valentina Roerich \\
Frank Danforth \\
\end{sqltable}

\begin{challenge}
  After further reading, we realize that Valentina Roerich was reporting
  salinity as percentages. Write a query that returns all of her
  salinity measurements from the \code{Survey} table with the values
  divided by 100.
\end{challenge}

\begin{challenge}
  The \code{union} operator combines the results of two queries:
\begin{VerbIn}
select * from Person where ident='dyer' union select * from Person where ident='roe';
\end{VerbIn}

\begin{sqltable}{lll}
dyer & William & Dyer \\
roe & Valentina & Roerich \\
\end{sqltable}

Use \code{union} to create a consolidated list of salinity
measurements in which Roerich's, and only Roerich's, have been corrected
as described in the previous challenge. The output should be something
like:

\begin{sqltable}{ll}
619 & 0.13 \\
622 & 0.09 \\
734 & 0.05 \\
751 & 0.1 \\
752 & 0.09 \\
752 & 0.416 \\
837 & 0.21 \\
837 & 0.225 \\
\end{sqltable}
\end{challenge}

\begin{challenge}
  The site identifiers in the \code{Visited} table have two parts
  separated by a `-':

\begin{VerbIn}
select distinct site from Visited;
\end{VerbIn}

\begin{sqltable}{l}
DR-1 \\
DR-3 \\
MSK-4 \\
\end{sqltable}

Some major site identifiers are two letters long and some are three. The
``in string'' function \code{instr(X, Y)} returns the 1-based index of
the first occurrence of string Y in string X, or 0 if Y does not exist
in X. The substring function \code{substr(X, I)} returns the substring
of X starting at index I. Use these two functions to produce a list of
unique major site identifiers. (For this data, the list should contain
only ``DR'' and ``MSK'').
\end{challenge}

\begin{keypoints}
\begin{swcitemize}
\item
  SQL can perform calculations using the values in a record as part of a
  query.
\end{swcitemize}
\end{keypoints}

\section{Missing Data}

\begin{objectives}
\begin{swcitemize}
\item
  Explain how databases represent missing information.
\item
  Explain the three-valued logic databases use when manipulating missing
  information.
\item
  Write queries that handle missing information correctly.
\end{swcitemize}
\end{objectives}

Real-world data is never complete---there are always holes. Databases
represent these holes using special value called \code{null}.
\code{null} is not zero, \code{False}, or the empty string; it is a
one-of-a-kind value that means ``nothing here''. Dealing with
\code{null} requires a few special tricks and some careful thinking.

To start, let's have a look at the \code{Visited} table. There are
eight records, but \#752 doesn't have a date---or rather, its date is
null:

\begin{VerbIn}
select * from Visited;
\end{VerbIn}

\begin{sqltable}{lll}
619 & DR-1 & 1927-02-08 \\
622 & DR-1 & 1927-02-10 \\
734 & DR-3 & 1939-01-07 \\
735 & DR-3 & 1930-01-12 \\
751 & DR-3 & 1930-02-26 \\
752 & DR-3 & ~ \\
837 & MSK-4 & 1932-01-14 \\
844 & DR-1 & 1932-03-22 \\
\end{sqltable}

Null doesn't behave like other values. If we select the records that
come before 1930:

\begin{VerbIn}
select * from Visited where dated<'1930-00-00';
\end{VerbIn}

\begin{sqltable}{lll}
619 & DR-1 & 1927-02-08 \\
622 & DR-1 & 1927-02-10 \\
\end{sqltable}

we get two results, and if we select the ones that come during or after
1930:

\begin{VerbIn}
select * from Visited where dated>='1930-00-00';
\end{VerbIn}

\begin{sqltable}{lll}
734 & DR-3 & 1939-01-07 \\
735 & DR-3 & 1930-01-12 \\
751 & DR-3 & 1930-02-26 \\
837 & MSK-4 & 1932-01-14 \\
844 & DR-1 & 1932-03-22 \\
\end{sqltable}

we get five, but record \#752 isn't in either set of results. The reason
is that \code{null\textless{}'1930-00-00'} is neither true nor false:
null means, ``We don't know,'' and if we don't know the value on the
left side of a comparison, we don't know whether the comparison is true
or false. Since databases represent ``don't know'' as null, the value of
\code{null\textless{}'1930-00-00'} is actually \code{null}.
\code{null\textgreater{}='1930-00-00'} is also null because we can't
answer to that question either. And since the only records kept by a
\code{where} are those for which the test is true, record \#752 isn't
included in either set of results.

Comparisons aren't the only operations that behave this way with nulls.
\code{1+null} is \code{null}, \code{5*null} is \code{null},
\code{log(null)} is \code{null}, and so on. In particular, comparing
things to null with = and != produces null:

\begin{VerbIn}
select * from Visited where dated=NULL;
\end{VerbIn}

% FIXME: empty table

\begin{VerbIn}
select * from Visited where dated!=NULL;
\end{VerbIn}

% FIXME: empty table

To check whether a value is \code{null} or not, we must use a special
test \code{is null}:

\begin{VerbIn}
select * from Visited where dated is NULL;
\end{VerbIn}

\begin{sqltable}{lll}
752 & DR-3 & ~ \\
\end{sqltable}

or its inverse \code{is not null}:

\begin{VerbIn}
select * from Visited where dated is not NULL;
\end{VerbIn}

\begin{sqltable}{lll}
619 & DR-1 & 1927-02-08 \\
622 & DR-1 & 1927-02-10 \\
734 & DR-3 & 1939-01-07 \\
735 & DR-3 & 1930-01-12 \\
751 & DR-3 & 1930-02-26 \\
837 & MSK-4 & 1932-01-14 \\
844 & DR-1 & 1932-03-22 \\
\end{sqltable}

Null values cause headaches wherever they appear. For example, suppose
we want to find all the salinity measurements that weren't taken by
Dyer. It's natural to write the query like this:

\begin{VerbIn}
select * from Survey where quant='sal' and person!='lake';
\end{VerbIn}

\begin{sqltable}{llll}
619 & dyer & sal & 0.13 \\
622 & dyer & sal & 0.09 \\
752 & roe & sal & 41.6 \\
837 & roe & sal & 22.5 \\
\end{sqltable}

but this query filters omits the records where we don't know who took
the measurement. Once again, the reason is that when \code{person} is
\code{null}, the \code{!=} comparison produces \code{null}, so the
record isn't kept in our results. If we want to keep these records we
need to add an explicit check:

\begin{VerbIn}
select * from Survey where quant='sal' and (person!='lake' or person is null);
\end{VerbIn}

\begin{sqltable}{llll}
619 & dyer & sal & 0.13 \\
622 & dyer & sal & 0.09 \\
735 & None & sal & 0.06 \\
752 & roe & sal & 41.6 \\
837 & roe & sal & 22.5 \\
\end{sqltable}

We still have to decide whether this is the right thing to do or not. If
we want to be absolutely sure that we aren't including any measurements
by Lake in our results, we need to exclude all the records for which we
don't know who did the work.

\begin{challenge}
  Write a query that sorts the records in \code{Visited} by date,
  omitting entries for which the date is not known (i.e., is null).
\end{challenge}

\begin{challenge}
  What do you expect the query:

\begin{VerbIn}
select * from Visited where dated in ('1927-02-08', null);
\end{VerbIn}

  to produce? What does it actually produce?
\end{challenge}

\begin{challenge}
  Some database designers prefer to use a
  \gl{sentinel value}{g:sentinel-value} to mark missing data
  rather than \code{null}. For example, they will use the date
  ``0000-00-00'' to mark a missing date, or -1.0 to mark a missing
  salinity or radiation reading (since actual readings cannot be
  negative). What does this simplify? What burdens or risks does it
  introduce?
\end{challenge}

\begin{keypoints}
\begin{swcitemize}
\item
  Databases use \code{null} to represent missing information.
\item
  Any arithmetic or Boolean operation involving \code{null} produces
  \code{null} as a result.
\item
  The only operators that can safely be used with \code{null} are
  \code{is null} and \code{is not null}.
\end{swcitemize}
\end{keypoints}

\section{Aggregation}

\begin{objectives}
\begin{swcitemize}
\item
  Define ``aggregation'' and give examples of its use.
\item
  Write queries that compute aggregated values.
\item
  Trace the execution of a query that performs aggregation.
\item
  Explain how missing data is handled during aggregation.
\end{swcitemize}
\end{objectives}

We now want to calculate ranges and averages for our data. We know how
to select all of the dates from the \code{Visited} table:

\begin{VerbIn}
select dated from Visited;
\end{VerbIn}

\begin{sqltable}{l}
1927-02-08 \\
1927-02-10 \\
1939-01-07 \\
1930-01-12 \\
1930-02-26 \\
~ \\
1932-01-14 \\
1932-03-22 \\
\end{sqltable}

but to combine them, wee must use an
\gl{aggregation function}{g:aggregation-function} such as
\code{min} or \code{max}. Each of these functions takes a set of
records as input, and produces a single record as output
(\figref{f:aggregate}):

\begin{VerbIn}
select min(dated) from Visited;
\end{VerbIn}

\begin{sqltable}{l}
1927-02-08 \\
\end{sqltable}

\swcgraphics{f:aggregate}{Aggregation in SQL}{novice/sql/img/sql-aggregation.pdf}{0.75}

\begin{VerbIn}
select max(dated) from Visited;
\end{VerbIn}

\begin{sqltable}{l}
1939-01-07 \\
\end{sqltable}

\code{min} and \code{max} are just two of the aggregation functions
built into SQL. Three others are \code{avg}, \code{count}, and
\code{sum}:

\begin{VerbIn}
select avg(reading) from Survey where quant='sal';
\end{VerbIn}

\begin{sqltable}{l}
7.20333333333 \\
\end{sqltable}

\begin{VerbIn}
select count(reading) from Survey where quant='sal';
\end{VerbIn}

\begin{sqltable}{l}
9 \\
\end{sqltable}

\begin{VerbIn}
select sum(reading) from Survey where quant='sal';
\end{VerbIn}

\begin{sqltable}{l}
64.83 \\
\end{sqltable}

We used \code{count(reading)} here, but we could just as easily have
counted \code{quant} or any other field in the table, or even used
\code{count(*)}, since the function doesn't care about the values
themselves, just how many values there are.

SQL lets us do several aggregations at once. We can, for example, find
the range of sensible salinity measurements:

\begin{VerbIn}
select min(reading), max(reading) from Survey where quant='sal' and reading<=1.0;
\end{VerbIn}

\begin{sqltable}{ll}
0.05 & 0.21 \\
\end{sqltable}

We can also combine aggregated results with raw results, although the
output might surprise you:

\begin{VerbIn}
select person, count(*) from Survey where quant='sal' and reading<=1.0;
\end{VerbIn}

\begin{sqltable}{ll}
lake & 7 \\
\end{sqltable}

Why does Lake's name appear rather than Roerich's or Dyer's? The answer
is that when it has to aggregate a field, but isn't told how to, the
database manager chooses an actual value from the input set. It might
use the first one processed, the last one, or something else entirely.

Another important fact is that when there are no values to aggregate,
aggregation's result is ``don't know'' rather than zero or some other
arbitrary value:

\begin{VerbIn}
select person, max(reading), sum(reading) from Survey where quant='missing';
\end{VerbIn}

\begin{sqltable}{lll}
~ & ~ & ~ \\
\end{sqltable}

One final important feature of aggregation functions is that they are
inconsistent with the rest of SQL in a very useful way. If we add two
values, and one of them is null, the result is null. By extension, if we
use \code{sum} to add all the values in a set, and any of those values
are null, the result should also be null. It's much more useful, though,
for aggregation functions to ignore null values and only combine those
that are non-null. This behavior lets us write our queries as:

\begin{VerbIn}
select min(dated) from Visited;
\end{VerbIn}

\begin{sqltable}{l}
1927-02-08 \\
\end{sqltable}

instead of always having to filter explicitly:

\begin{VerbIn}
select min(dated) from Visited where dated is not null;
\end{VerbIn}

\begin{sqltable}{l}
1927-02-08 \\
\end{sqltable}

Aggregating all records at once doesn't always make sense. For example,
suppose Gina suspects that there is a systematic bias in her data, and
that some scientists' radiation readings are higher than others. We know
that this doesn't work:

\begin{VerbIn}
select person, count(reading), round(avg(reading), 2)
from  Survey
where quant='rad';
\end{VerbIn}

\begin{sqltable}{lll}
roe & 8 & 6.56 \\
\end{sqltable}

because the database manager selects a single arbitrary scientist's name
rather than aggregating separately for each scientist. Since there are
only five scientists, she could write five queries of the form:

\begin{VerbIn}
select person, count(reading), round(avg(reading), 2)
from  Survey
where quant='rad'
and   person='dyer';
\end{VerbIn}

\begin{sqltable}{lll}
dyer & 2 & 8.81 \\
\end{sqltable}

but this would be tedious, and if she ever had a data set with fifty or
five hundred scientists, the chances of her getting all of those queries
right is small.

What we need to do is tell the database manager to aggregate the hours
for each scientist separately using a \code{group by} clause:

\begin{VerbIn}
select   person, count(reading), round(avg(reading), 2)
from     Survey
where    quant='rad'
group by person;
\end{VerbIn}

\begin{sqltable}{lll}
dyer & 2 & 8.81 \\
lake & 2 & 1.82 \\
pb & 3 & 6.66 \\
roe & 1 & 11.25 \\
\end{sqltable}

\code{group by} does exactly what its name implies: groups all the
records with the same value for the specified field together so that
aggregation can process each batch separately. Since all the records in
each batch have the same value for \code{person}, it no longer matters
that the database manager is picking an arbitrary one to display
alongside the aggregated \code{reading} values.

Just as we can sort by multiple criteria at once, we can also group by
multiple criteria. To get the average reading by scientist and quantity
measured, for example, we just add another field to the
\code{group by} clause:

\begin{VerbIn}
select   person, quant, count(reading), round(avg(reading), 2)
from     Survey
group by person, quant;
\end{VerbIn}

\begin{sqltable}{llll}
~ & sal & 1 & 0.06 \\
~ & temp & 1 & -26.0 \\
dyer & rad & 2 & 8.81 \\
dyer & sal & 2 & 0.11 \\
lake & rad & 2 & 1.82 \\
lake & sal & 4 & 0.11 \\
lake & temp & 1 & -16.0 \\
pb & rad & 3 & 6.66 \\
pb & temp & 2 & -20.0 \\
roe & rad & 1 & 11.25 \\
roe & sal & 2 & 32.05 \\
\end{sqltable}

Note that we have added \code{person} to the list of fields displayed,
since the results wouldn't make much sense otherwise.

Let's go one step further and remove all the entries where we don't know
who took the measurement:

\begin{VerbIn}
select   person, quant, count(reading), round(avg(reading), 2)
from     Survey
where    person is not null
group by person, quant
order by person, quant;
\end{VerbIn}

\begin{sqltable}{llll}
dyer & rad & 2 & 8.81 \\
dyer & sal & 2 & 0.11 \\
lake & rad & 2 & 1.82 \\
lake & sal & 4 & 0.11 \\
lake & temp & 1 & -16.0 \\
pb & rad & 3 & 6.66 \\
pb & temp & 2 & -20.0 \\
roe & rad & 1 & 11.25 \\
roe & sal & 2 & 32.05 \\
\end{sqltable}

Looking more closely, this query:

\begin{swcenumerate}
\item
  selected records from the \code{Survey} table where the
  \code{person} field was not null;
\item
  grouped those records into subsets so that the \code{person} and
  \code{quant} values in each subset were the same;
\item
  ordered those subsets first by \code{person}, and then within each
  sub-group by \code{quant}; and
\item
  counted the number of records in each subset, calculated the average
  \code{reading} in each, and chose a \code{person} and
  \code{quant} value from each (it doesn't matter which ones, since
  they're all equal).
\end{swcenumerate}

\begin{challenge}
  How many temperature readings did Frank Pabodie record, and what was
  their average value?
\end{challenge}

\begin{challenge}
  The average of a set of values is the sum of the values divided by the
  number of values. Does this mean that the \code{avg} function
  returns 2.0 or 3.0 when given the values 1.0, \code{null}, and 5.0?
\end{challenge}

\begin{challenge}
  We want to calculate the difference between each individual radiation
  reading and the average of all the radiation readings. We write the
  query:

\begin{VerbIn}
select reading - avg(reading) from Survey where quant='rad';
\end{VerbIn}

  What does this actually produce, and why?
\end{challenge}

\begin{challenge}
  The function \code{group\_concat(field, separator)} concatenates all
  the values in a field using the specified separator character (or `,'
  if the separator isn't specified). Use this to produce a one-line list
  of scientists' names, such as:

\begin{VerbIn}
William Dyer, Frank Pabodie, Anderson Lake, Valentina Roerich, Frank Danforth
\end{VerbIn}

  Can you find a way to order the list by surname?
\end{challenge}

\begin{keypoints}
\begin{swcitemize}
\item
  An aggregation function combines many values to produce a single new
  value.
\item
  Aggregation functions ignore \code{null} values.
\item
  Aggregation happens after filtering.
\end{swcitemize}
\end{keypoints}

\section{Combining Data}

\begin{objectives}
\begin{swcitemize}
\item
  Explain the operation of a query that joins two tables.
\item
  Explain how to restrict the output of a query containing a join to
  only include meaningful combinations of values.
\item
  Write queries that join tables on equal keys.
\item
  Explain what primary and foreign keys are, and why they are useful.
\item
  Explain what atomic values are, and why database fields should only
  contain atomic values.
\end{swcitemize}
\end{objectives}

In order to submit her data to a web site that aggregates historical
meteorological data, Gina needs to format it as latitude, longitude,
date, quantity, and reading. However, her latitudes and longitudes are
in the \code{Site} table, while the dates of measurements are in the
\code{Visited} table and the readings themselves are in the
\code{Survey} table. She needs to combine these tables somehow.

The SQL command to do this is \code{join}. To see how it works, let's
start by joining the \code{Site} and \code{Visited} tables:

\begin{VerbIn}
select * from Site join Visited;
\end{VerbIn}

\begin{sqltable}{llllll}
DR-1 & -49.85 & -128.57 & 619 & DR-1 & 1927-02-08 \\
DR-1 & -49.85 & -128.57 & 622 & DR-1 & 1927-02-10 \\
DR-1 & -49.85 & -128.57 & 734 & DR-3 & 1939-01-07 \\
DR-1 & -49.85 & -128.57 & 735 & DR-3 & 1930-01-12 \\
DR-1 & -49.85 & -128.57 & 751 & DR-3 & 1930-02-26 \\
DR-1 & -49.85 & -128.57 & 752 & DR-3 & ~ \\
DR-1 & -49.85 & -128.57 & 837 & MSK-4 & 1932-01-14 \\
DR-1 & -49.85 & -128.57 & 844 & DR-1 & 1932-03-22 \\
DR-3 & -47.15 & -126.72 & 619 & DR-1 & 1927-02-08 \\
DR-3 & -47.15 & -126.72 & 622 & DR-1 & 1927-02-10 \\
DR-3 & -47.15 & -126.72 & 734 & DR-3 & 1939-01-07 \\
DR-3 & -47.15 & -126.72 & 735 & DR-3 & 1930-01-12 \\
DR-3 & -47.15 & -126.72 & 751 & DR-3 & 1930-02-26 \\
DR-3 & -47.15 & -126.72 & 752 & DR-3 & ~ \\
DR-3 & -47.15 & -126.72 & 837 & MSK-4 & 1932-01-14 \\
DR-3 & -47.15 & -126.72 & 844 & DR-1 & 1932-03-22 \\
MSK-4 & -48.87 & -123.4 & 619 & DR-1 & 1927-02-08 \\
MSK-4 & -48.87 & -123.4 & 622 & DR-1 & 1927-02-10 \\
MSK-4 & -48.87 & -123.4 & 734 & DR-3 & 1939-01-07 \\
MSK-4 & -48.87 & -123.4 & 735 & DR-3 & 1930-01-12 \\
MSK-4 & -48.87 & -123.4 & 751 & DR-3 & 1930-02-26 \\
MSK-4 & -48.87 & -123.4 & 752 & DR-3 & ~ \\
MSK-4 & -48.87 & -123.4 & 837 & MSK-4 & 1932-01-14 \\
MSK-4 & -48.87 & -123.4 & 844 & DR-1 & 1932-03-22 \\
\end{sqltable}

\code{join} creates the \gl{cross product}{g:cross-product} of
two tables, i.e., it joins each record of one with each record of the
other to give all possible combinations. Since there are three records
in \code{Site} and eight in \code{Visited}, the join's output has 24
records. And since each table has three fields, the output has six
fields.

What the join \emph{hasn't} done is figure out if the records being
joined have anything to do with each other. It has no way of knowing
whether they do or not until we tell it how. To do that, we add a clause
specifying that we're only interested in combinations that have the same
site name:

\begin{VerbIn}
select * from Site join Visited on Site.name=Visited.site;
\end{VerbIn}

\begin{sqltable}{llllll}
DR-1 & -49.85 & -128.57 & 619 & DR-1 & 1927-02-08 \\
DR-1 & -49.85 & -128.57 & 622 & DR-1 & 1927-02-10 \\
DR-1 & -49.85 & -128.57 & 844 & DR-1 & 1932-03-22 \\
DR-3 & -47.15 & -126.72 & 734 & DR-3 & 1939-01-07 \\
DR-3 & -47.15 & -126.72 & 735 & DR-3 & 1930-01-12 \\
DR-3 & -47.15 & -126.72 & 751 & DR-3 & 1930-02-26 \\
DR-3 & -47.15 & -126.72 & 752 & DR-3 & ~ \\
MSK-4 & -48.87 & -123.4 & 837 & MSK-4 & 1932-01-14 \\
\end{sqltable}

\code{on} does the same job as \code{where}: it only keeps records
that pass some test. (The difference between the two is that \code{on}
filters records as they're being created, while \code{where} waits
until the join is done and then does the filtering.) Once we add this to
our query, the database manager throws away records that combined
information about two different sites, leaving us with just the ones we
want.

Notice that we used \code{table.field} to specify field names in the
output of the join. We do this because tables can have fields with the
same name, and we need to be specific which ones we're talking about.
For example, if we joined the \code{person} and \code{visited}
tables, the result would inherit a field called \code{ident} from each
of the original tables.

We can now use the same dotted notation to select the three columns we
actually want out of our join:

\begin{VerbIn}
select Site.lat, Site.long, Visited.dated
from   Site join Visited
on     Site.name=Visited.site;
\end{VerbIn}

\begin{sqltable}{lll}
-49.85 & -128.57 & 1927-02-08 \\
-49.85 & -128.57 & 1927-02-10 \\
-49.85 & -128.57 & 1932-03-22 \\
-47.15 & -126.72 & ~ \\
-47.15 & -126.72 & 1930-01-12 \\
-47.15 & -126.72 & 1930-02-26 \\
-47.15 & -126.72 & 1939-01-07 \\
-48.87 & -123.4 & 1932-01-14 \\
\end{sqltable}

If joining two tables is good, joining many tables must be better. In
fact, we can join any number of tables simply by adding more
\code{join} clauses to our query, and more \code{on} tests to filter
out combinations of records that don't make sense:

\begin{VerbIn}
select Site.lat, Site.long, Visited.dated, Survey.quant, Survey.reading
from   Site join Visited join Survey
on     Site.name=Visited.site
and    Visited.ident=Survey.taken
and    Visited.dated is not null;
\end{VerbIn}

\begin{sqltable}{lllll}
-49.85 & -128.57 & 1927-02-08 & rad & 9.82 \\
-49.85 & -128.57 & 1927-02-08 & sal & 0.13 \\
-49.85 & -128.57 & 1927-02-10 & rad & 7.8 \\
-49.85 & -128.57 & 1927-02-10 & sal & 0.09 \\
-47.15 & -126.72 & 1939-01-07 & rad & 8.41 \\
-47.15 & -126.72 & 1939-01-07 & sal & 0.05 \\
-47.15 & -126.72 & 1939-01-07 & temp & -21.5 \\
-47.15 & -126.72 & 1930-01-12 & rad & 7.22 \\
-47.15 & -126.72 & 1930-01-12 & sal & 0.06 \\
-47.15 & -126.72 & 1930-01-12 & temp & -26.0 \\
-47.15 & -126.72 & 1930-02-26 & rad & 4.35 \\
-47.15 & -126.72 & 1930-02-26 & sal & 0.1 \\
-47.15 & -126.72 & 1930-02-26 & temp & -18.5 \\
-48.87 & -123.4 & 1932-01-14 & rad & 1.46 \\
-48.87 & -123.4 & 1932-01-14 & sal & 0.21 \\
-48.87 & -123.4 & 1932-01-14 & sal & 22.5 \\
-49.85 & -128.57 & 1932-03-22 & rad & 11.25 \\
\end{sqltable}

We can tell which records from \code{Site}, \code{Visited}, and
\code{Survey} correspond with each other because those tables contain
\gl{primary keys}{g:primary-key} and
\gl{foreign keys}{g:foreign-key}. A primary key is a value, or
combination of values, that uniquely identifies each record in a table.
A foreign key is a value (or combination of values) from one table that
identifies a unique record in another table. Another way of saying this
is that a foreign key is the primary key of one table that appears in
some other table. In our database, \code{Person.ident} is the primary
key in the \code{Person} table, while \code{Survey.person} is a
foreign key relating the \code{Survey} table's entries to entries in
\code{Person}.

Most database designers believe that every table should have a
well-defined primary key. They also believe that this key should be
separate from the data itself, so that if we ever need to change the
data, we only need to make one change in one place. One easy way to do
this is to create an arbitrary, unique ID for each record as we add it
to the database. This is actually very common: those IDs have names like
``student numbers'' and ``patient numbers'', and they almost always turn
out to have originally been a unique record identifier in some database
system or other. As the query below demonstrates, SQLite automatically
numbers records as they're added to tables, and we can use those record
numbers in queries:

\begin{VerbIn}
select rowid, * from Person;
\end{VerbIn}

\begin{sqltable}{llll}
1 & dyer & William & Dyer \\
2 & pb & Frank & Pabodie \\
3 & lake & Anderson & Lake \\
4 & roe & Valentina & Roerich \\
5 & danforth & Frank & Danforth \\
\end{sqltable}

\subsection{Data Hygiene}

Now that we have seen how joins work, we can see why the relational
model is so useful and how best to use it. The first rule is that every
value should be \gl{atomic}{g:atomic-value}, i.e., not contain
parts that we might want to work with separately. We store personal and
family names in separate columns instead of putting the entire name in
one column so that we don't have to use substring operations to get the
name's components. More importantly, we store the two parts of the name
separately because splitting on spaces is unreliable: just think of a
name like ``Eloise St. Cyr'' or ``Jan Mikkel Steubart''.

The second rule is that every record should have a unique primary key.
This can be a serial number that has no intrinsic meaning, one of the
values in the record (like the \code{ident} field in the
\code{Person} table), or even a combination of values: the triple
\code{(taken, person, quant)} from the \code{Survey} table uniquely
identifies every measurement.

The third rule is that there should be no redundant information. For
example, we could get rid of the \code{Site} table and rewrite the
\code{Visited} table like this:

\begin{sqltable}{llll}
619 & -49.85 & -128.57 & 1927-02-08 \\
622 & -49.85 & -128.57 & 1927-02-10 \\
734 & -47.15 & -126.72 & 1939-01-07 \\
735 & -47.15 & -126.72 & 1930-01-12 \\
751 & -47.15 & -126.72 & 1930-02-26 \\
752 & -47.15 & -126.72 & ~ \\
837 & -48.87 & -123.40 & 1932-01-14 \\
844 & -49.85 & -128.57 & 1932-03-22 \\
\end{sqltable}

In fact, we could use a single table that recorded all the information
about each reading in each row, just as a spreadsheet would. The problem
is that it's very hard to keep data organized this way consistent: if we
realize that the date of a particular visit to a particular site is
wrong, we have to change multiple records in the database. What's worse,
we may have to guess which records to change, since other sites may also
have been visited on that date.

The fourth rule is that the units for every value should be stored
explicitly. Our database doesn't do this, and that's a problem:
Roerich's salinity measurements are several orders of magnitude larger
than anyone else's, but we don't know if that means she was using parts
per million instead of parts per thousand, or whether there actually was
a saline anomaly at that site in 1932.

Stepping back, data and the tools used to store it have a symbiotic
relationship: we use tables and joins because it's efficient, provided
our data is organized a certain way, but organize our data that way
because we have tools to manipulate it efficiently if it's in a certain
form. As anthropologists say, the tool shapes the hand that shapes the
tool.

\begin{challenge}
  Write a query that lists all radiation readings from the DR-1 site.
\end{challenge}

\begin{challenge}
  Write a query that lists all sites visited by people named ``Frank''.
\end{challenge}

\begin{challenge}
  Describe in your own words what the following query produces:

\begin{VerbIn}
select Site.name from Site join Visited
on Site.lat<-49.0 and Site.name=Visited.site and Visited.dated>='1932-00-00';
\end{VerbIn}
\end{challenge}

\begin{keypoints}
\begin{swcitemize}
\item
  Every fact should be represented in a database exactly once.
\item
  A join produces all combinations of records from one table with
  records from another.
\item
  A primary key is a field (or set of fields) whose values uniquely
  identify the records in a table.
\item
  A foreign key is a field (or set of fields) in one table whose values
  are a primary key in another table.
\item
  We can eliminate meaningless combinations of records by matching
  primary keys and foreign keys between tables.
\item
  Keys should be atomic values to make joins simpler and more efficient.
\end{swcitemize}
\end{keypoints}

\section{Creating and Modifying Data}

\begin{objectives}
\begin{swcitemize}
\item
  Write queries that creates tables.
\item
  Write queries to insert, modify, and delete records.
\end{swcitemize}
\end{objectives}

So far we have only looked at how to get information out of a database,
both because that is more frequent than adding information, and because
most other operations only make sense once queries are understood. If we
want to create and modify data, we need to know two other pairs of
commands.

The first pair are \code{create table} and \code{drop table}. While
they are written as two words, they are actually single commands. The
first one creates a new table; its arguments are the names and types of
the table's columns. For example, the following statements create the
four tables in our survey database:

\begin{VerbIn}
create table Person(ident text, personal text, family text);
create table Site(name text, lat real, long real);
create table Visited(ident integer, site text, dated text);
create table Survey(taken integer, person text, quant real, reading real);
\end{VerbIn}

We can get rid of one of our tables using:

\begin{VerbIn}
drop table Survey;
\end{VerbIn}

Be very careful when doing this: most databases have some support for
undoing changes, but it's better not to have to rely on it.

Different database systems support different data types for table
columns, but most provide the following:

\begin{tabular}{ll}
integer & a signed integer \\
real & a floating point number \\
text & a character string \\
blob & a ``binary large object'', such as an image \\
\end{tabular}

Most databases also support Booleans and date/time values; SQLite uses
the integers 0 and 1 for the former, and represents the latter as
discussed \gl{earlier}{a:dates}. An increasing number of databases
also support geographic data types, such as latitude and longitude.
Keeping track of what particular systems do or do not offer, and what
names they give different data types, is an unending portability
headache.

When we create a table, we can specify several kinds of constraints on
its columns. For example, a better definition for the \code{Survey}
table would be:

\begin{VerbIn}
create table Survey(
    taken   integer not null, -- where reading taken
    person  text,             -- may not know who took it
    quant   real not null,    -- the quantity measured
    reading real not null,    -- the actual reading
    primary key(taken, quant),
    foreign key(taken) references Visited(ident),
    foreign key(person) references Person(ident)
);
\end{VerbIn}

Once again, exactly what constraints are avialable and what they're
called depends on which database manager we are using.

Once tables have been created, we can add and remove records using our
other pair of commands, \code{insert} and \code{delete}. The
simplest form of \code{insert} statement lists values in order:

\begin{VerbIn}
insert into Site values('DR-1', -49.85, -128.57);
insert into Site values('DR-3', -47.15, -126.72);
insert into Site values('MSK-4', -48.87, -123.40);
\end{VerbIn}

We can also insert values into one table directly from another:

\begin{VerbIn}
create table JustLatLong(lat text, long text);
insert into JustLatLong select lat, long from site;
\end{VerbIn}

Deleting records can be a bit trickier, because we have to ensure that
the database remains internally consistent. If all we care about is a
single table, we can use the \code{delete} command with a
\code{where} clause that matches the records we want to discard. For
example, once we realize that Frank Danforth didn't take any
measurements, we can remove him from the \code{Person} table like
this:

\begin{VerbIn}
delete from Person where ident = "danforth";
\end{VerbIn}

But what if we removed Anderson Lake instead? Our \code{Survey} table
would still contain seven records of measurements he'd taken, but that's
never supposed to happen: \code{Survey.person} is a foreign key into
the \code{Person} table, and all our queries assume there will be a
row in the latter matching every value in the former.

This problem is called \gl{referential
integrity}{g:referential-integrity}: we need to ensure that all references between tables can
always be resolved correctly. One way to do this is to delete all the
records that use \code{'lake'} as a foreign key before deleting the
record that uses it as a primary key. If our database manager supports
it, we can automate this using \gl{cascading
delete}{g:cascading-delete}. However, this technique is outside the scope of this chapter.

\begin{swcbox}{Mix and Match}

Many applications use a hybrid storage model instead of putting
everything into a database: the actual data (such as astronomical
images) is stored in files, while the database stores the files' names,
their modification dates, the region of the sky they cover, their
spectral characteristics, and so on. This is also how most music player
software is built: the database inside the application keeps track of
the MP3 files, but the files themselves live on disk.

\end{swcbox}

\begin{challenge}
  Write an SQL statement to replace all uses of \code{null} in
  \code{Survey.person} with the string \code{'unknown'}.
\end{challenge}

\begin{challenge}
  One of our colleagues has sent us a \gl{CSV}{g:csv} file
  containing temperature readings by Robert Olmstead, which is formatted
  like this:

\begin{VerbFile}
Taken,Temp
619,-21.5
622,-15.5
\end{VerbFile}

  Write a small Python program that reads this file in and prints out
  the SQL \code{insert} statements needed to add these records to the
  survey database. Note: you will need to add an entry for Olmstead to
  the \code{Person} table. If you are testing your program repeatedly,
  you may want to investigate SQL's \code{insert or replace} command.
\end{challenge}

\begin{challenge}
  SQLite has several administrative commands that aren't part of the SQL
  standard. One of them is \code{.dump}, which prints the SQL commands
  needed to re-create the database. Another is \code{.load}, which
  reads a file created by \code{.dump} and restores the database. A
  colleague of yours thinks that storing dump files (which are text) in
  version control is a good way to track and manage changes to the
  database. What are the pros and cons of this approach? (Hint: records
  aren't stored in any particular order.)
\end{challenge}

\begin{keypoints}
\begin{swcitemize}
\item
  Database tables are created using queries that specify their names and
  the names and properties of their fields.
\item
  Records can be inserted, updated, or deleted using queries.
\item
  It is simpler and safer to modify data when every record has a unique
  primary key.
\end{swcitemize}
\end{keypoints}

\section{Programming with Databases}

\begin{objectives}
\begin{swcitemize}
\item
  Write short programs that execute SQL queries.
\item
  Trace the execution of a program that contains an SQL query.
\item
  Explain why most database applications are written in a
  general-purpose language rather than in SQL.
\end{swcitemize}
\end{objectives}

To close, let's have a look at how to access a database from a
general-purpose programming language like Python. Other languages use
almost exactly the same model: library and function names may differ,
but the concepts are the same.

Here's a short Python program that selects latitudes and longitudes from
an SQLite database stored in a file called \code{survey.db}:

\begin{VerbIn}
import sqlite3
connection = sqlite3.connect("survey.db")
cursor = connection.cursor()
cursor.execute("select site.lat, site.long from site;")
results = cursor.fetchall()
for r in results:
    print r
cursor.close()
connection.close()
\end{VerbIn}

\begin{VerbOut}
(-49.85, -128.57)
(-47.15, -126.72)
(-48.87, -123.4)
\end{VerbOut}

The program starts by importing the \code{sqlite3} library. If we were
connecting to MySQL, DB2, or some other database, we would import a
different library, but all of them provide the same functions, so that
the rest of our program does not have to change (at least, not much) if
we switch from one database to another.

Line 2 establishes a connection to the database. Since we're using
SQLite, all we need to specify is the name of the database file. Other
systems may require us to provide a username and password as well. Line
3 then uses this connection to create a \gl{cursor}{g:cursor};
just like the cursor in an editor, its role is to keep track of where we
are in the database.

On line 4, we use that cursor to ask the database to execute a query for
us. The query is written in SQL, and passed to \code{cursor.execute}
as a string. It's our job to make sure that SQL is properly formatted;
if it isn't, or if something goes wrong when it is being executed, the
database will report an error.

The database returns the results of the query to us in response to the
\code{cursor.fetchall} call on line 5. This result is a list with one
entry for each record in the result set; if we loop over that list (line
6) and print those list entries (line 7), we can see that each one is a
tuple with one element for each field we asked for.

Finally, lines 8 and 9 close our cursor and our connection, since the
database can only keep a limited number of these open at one time. Since
establishing a connection takes time, though, we shouldn't open a
connection, do one operation, then close the connection, only to reopen
it a few microseconds later to do another operation. Instead, it's
normal to create one connection that stays open for the lifetime of the
program.

Queries in real applications will often depend on values provided by
users. For example, this function takes a user's ID as a parameter and
returns their name:

\begin{VerbIn}
def get_name(database_file, person_ident):
    query = "select personal || ' ' || family from Person where ident='" + person_ident + "';"

    connection = sqlite3.connect(database_file)
    cursor = connection.cursor()
    cursor.execute(query)
    results = cursor.fetchall()
    cursor.close()
    connection.close()

    return results[0][0]

print "full name for dyer:", get_name('survey.db', 'dyer')
\end{VerbIn}

\begin{VerbOut}
full name for dyer: William Dyer
\end{VerbOut}

We use string concatenation on the first line of this function to
construct a query containing the user ID we have been given. This seems
simple enough, but what happens if someone gives us this string as
input?

\begin{VerbOut}
dyer'; drop table Survey; select '
\end{VerbOut}

It looks like there's garbage after the name of the project, but it is
very carefully chosen garbage. If we insert this string into our query,
the result is:

\begin{VerbIn}
select personal || ' ' || family from Person where ident='dyer'; drop tale Survey; select '';
\end{VerbIn}

If we execute this, it will erase one of the tables in our database.

This is called an \gl{SQL injection
attack}{g:sql-injection-attack}, and it has been used to attack thousands of programs over the
years. In particular, many web sites that take data from users insert
values directly into queries without checking them carefully first.

Since a villain might try to smuggle commands into our queries in many
different ways, the safest way to deal with this threat is to replace
characters like quotes with their escaped equivalents, so that we can
safely put whatever the user gives us inside a string. We can do this by
using a \gl{prepared statement}{g:prepared-statement} instead of
formatting our statements as strings. Here's what our example program
looks like if we do this:

\begin{VerbIn}
def get_name(database_file, person_ident):
    query = "select personal || ' ' || family from Person where ident=?;"

    connection = sqlite3.connect(database_file)
    cursor = connection.cursor()
    cursor.execute(query, [person_ident])
    results = cursor.fetchall()
    cursor.close()
    connection.close()

    return results[0][0]

print "full name for dyer:", get_name('survey.db', 'dyer')
\end{VerbIn}

\begin{VerbOut}
full name for dyer: William Dyer
\end{VerbOut}

The key changes are in the query string and the \code{execute} call.
Instead of formatting the query ourselves, we put question marks in the
query template where we want to insert values. When we call
\code{execute}, we provide a list that contains as many values as
there are question marks in the query. The library matches values to
question marks in order, and translates any special characters in the
values into their escaped equivalents so that they are safe to use.

\begin{challenge}
  Write a Python program that creates a new database in a file called
  \code{original.db} containing a single table called
  \code{Pressure}, with a single field called \code{reading}, and
  inserts 100,000 random numbers between 10.0 and 25.0. How long does it
  take this program to run? How long does it take to run a program that
  simply writes those random numbers to a file?
\end{challenge}

\begin{challenge}
  Write a Python program that creates a new database called
  \code{backup.db} with the same structure as \code{original.db} and
  copies all the values greater than 20.0 from \code{original.db} to
  \code{backup.db}. Which is faster: filtering values in the query, or
  reading everything into memory and filtering in Python?
\end{challenge}

\begin{keypoints}
\begin{swcitemize}
\item
  We usually write database applications in a general-purpose language,
  and embed SQL queries in it.
\item
  To connect to a database, a program must use a library specific to
  that database manager.
\item
  A program may open one or more connections to a single database, and
  have one or more cursors active in each.
\item
  Programs can read query results in batches or all at once.
\end{swcitemize}
\end{keypoints}
